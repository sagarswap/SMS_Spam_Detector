{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/SMSSpamCollection.txt\")\n",
    "labels=[]\n",
    "sms=[]\n",
    "while True:\n",
    "\tcontent=file.readline().lower()\n",
    "\tif not content:\n",
    "\t\tbreak\n",
    "\tsms.append(content[4:].replace(\"\\n\", \"\"))\n",
    "\tlabels.append(content[:4].replace(\"\\t\", \"\"))\n",
    "file.close()\n",
    "sms=[s.replace(\"\\t\", \"\") for s in sms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate TF-IDF Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "stopWords=set(stopwords.words(\"english\"))\n",
    "idf={}\n",
    "tfidf_temp=[]\n",
    "tfidf=[]\n",
    "for sm in sms:\n",
    "    words=word_tokenize(sm)\n",
    "    wc=0\n",
    "    tf={}\n",
    "    for word in words:\n",
    "        word=ps.stem(word)\n",
    "        if word in stopWords:\n",
    "            continue\n",
    "        wc+=1\n",
    "        if word in tf:\n",
    "            tf[word]+=1\n",
    "        else:\n",
    "            tf[word]=1\n",
    "    for key in tf:\n",
    "        tf[key]/=wc\n",
    "        if key in idf:\n",
    "            idf[key]+=1\n",
    "        else:\n",
    "            idf[key]=1\n",
    "    tfidf_temp.append(tf)\n",
    "for key in idf:\n",
    "    idf[key]=math.log(len(sms)/idf[key])\n",
    "\n",
    "for x in tfidf_temp:\n",
    "    for key in idf:\n",
    "        if key in x:\n",
    "            x[key]*=idf[key]\n",
    "        else:\n",
    "            x[key]=0\n",
    "    myKeys = list(x.keys())\n",
    "    myKeys.sort()\n",
    "    sorted_dict = {i: x[i] for i in myKeys}\n",
    "    tfidf.append(sorted_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5016\n",
      "558\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix=[]\n",
    "for x in tfidf:\n",
    "    mat_row=[]\n",
    "    for key in x:\n",
    "        mat_row.append(x[key])\n",
    "    tfidf_matrix.append(mat_row)\n",
    "file=open(\"TF-IDF Matrix.txt\", 'w')\n",
    "for items in tfidf_matrix:\n",
    "    for item in items:\n",
    "        stringer=str(item)+\" \"\n",
    "        file.write(stringer)\n",
    "    file.write(\"\\n\")\n",
    "file.close()\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, labels, random_state=109, test_size=0.1, shuffle=True)\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9247311827956989\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, y_train)\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data, k, max_iterations=100):\n",
    "    # Randomly initialize the cluster centers\n",
    "    centroids = data[np.random.choice(data.shape[0], k, replace=False)]\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Assign each data point to the nearest centroid\n",
    "        distances = np.linalg.norm(data[:, np.newaxis] - centroids, axis=2)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "\n",
    "        # Update the centroids by taking the mean of all points assigned to each centroid\n",
    "        new_centroids = np.array([data[labels == i].mean(axis=0) for i in range(k)])\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.all(centroids == new_centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return centroids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final centroids:\n",
      "[[0.02976892 0.00811047 0.00108374 ... 0.00179904 0.0009198  0.00030348]\n",
      " [0.02165719 0.         0.         ... 0.         0.         0.        ]]\n",
      "Accuracy of K-Means =  85.2529601722282\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "np_matrix=np.array([np.array(xi) for xi in tfidf_matrix])\n",
    "centroids, labelss = kmeans(np_matrix, k)\n",
    "print(\"Final centroids:\")\n",
    "print(centroids)\n",
    "c1=0\n",
    "c2=0\n",
    "count=0\n",
    "for lab in labelss:\n",
    "    if lab==0:\n",
    "        c1+=1\n",
    "    else:\n",
    "        c2+=1\n",
    "if(c1>c2):\n",
    "    for i in range(0, len(tfidf_matrix)):\n",
    "        if labelss[i]==0 and labels[i]==\"ham\":\n",
    "            count+=1\n",
    "        elif labelss[i]==1 and labels[i]==\"spam\":\n",
    "            count+=1\n",
    "else:\n",
    "    for i in range(0, len(tfidf_matrix)):\n",
    "        if labelss[i]==1 and labels[i]==\"ham\":\n",
    "            count+=1\n",
    "        elif labelss[i]==0 and labels[i]==\"spam\":\n",
    "            count+=1\n",
    "print(\"Accuracy of K-Means = \", (count*100/len(tfidf_matrix)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
